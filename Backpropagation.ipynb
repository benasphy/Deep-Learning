{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benasphy/Deep-Learning/blob/main/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jiltZ1V0rh3",
        "outputId": "f52da8f8-ecf7-45b5-bd12-49b0801b2745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.0698\n",
            "Epoch 20, Loss: 0.0192\n",
            "Epoch 30, Loss: 0.0163\n",
            "Epoch 40, Loss: 0.0142\n",
            "Epoch 50, Loss: 0.0127\n",
            "Epoch 60, Loss: 0.0116\n",
            "Epoch 70, Loss: 0.0107\n",
            "Epoch 80, Loss: 0.0100\n",
            "Epoch 90, Loss: 0.0096\n",
            "Epoch 100, Loss: 0.0092\n",
            "Final weights: [<KerasVariable shape=(1, 1), dtype=float32, path=simple_nn_4/dense_4/kernel>, <KerasVariable shape=(1,), dtype=float32, path=simple_nn_4/dense_4/bias>]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Generate dummy data\n",
        "np.random.seed(42)\n",
        "X_data = np.random.rand(100, 1)  # 100 samples, 1 feature\n",
        "y_data = 3 * X_data + 2 + np.random.normal(0, 0.1, (100, 1))  # y = 3x + 2 + noise\n",
        "\n",
        "# Define the model\n",
        "class SimpleNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(1, activation=None)  # One neuron, linear activation\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense1(inputs)\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = SimpleNN()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "# Loss function: Mean Squared Error (MSE)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(X_data)  # Forward pass\n",
        "        loss = loss_fn(y_data, predictions)  # Calculate loss\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Apply gradients to update weights\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {loss.numpy():.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Final weights:\", model.dense1.weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrwGCvN23vGb",
        "outputId": "5c66d4b7-050e-42c9-aa62-c880b246bf41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "Step 0, Loss: 2.3039\n",
            "Step 100, Loss: 1.0310\n",
            "Step 200, Loss: 0.8212\n",
            "Step 300, Loss: 0.5551\n",
            "Step 400, Loss: 0.2880\n",
            "Step 500, Loss: 0.2601\n",
            "Step 600, Loss: 0.3368\n",
            "Step 700, Loss: 0.1361\n",
            "Step 800, Loss: 0.1875\n",
            "Step 900, Loss: 0.2607\n",
            "Epoch 2/3\n",
            "Step 0, Loss: 0.2363\n",
            "Step 100, Loss: 0.1359\n",
            "Step 200, Loss: 0.1167\n",
            "Step 300, Loss: 0.2300\n",
            "Step 400, Loss: 0.2118\n",
            "Step 500, Loss: 0.1315\n",
            "Step 600, Loss: 0.1994\n",
            "Step 700, Loss: 0.1218\n",
            "Step 800, Loss: 0.2886\n",
            "Step 900, Loss: 0.1929\n",
            "Epoch 3/3\n",
            "Step 0, Loss: 0.0271\n",
            "Step 100, Loss: 0.1546\n",
            "Step 200, Loss: 0.1089\n",
            "Step 300, Loss: 0.0991\n",
            "Step 400, Loss: 0.0684\n",
            "Step 500, Loss: 0.2782\n",
            "Step 600, Loss: 0.0632\n",
            "Step 700, Loss: 0.0746\n",
            "Step 800, Loss: 0.1291\n",
            "Step 900, Loss: 0.0675\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9576 - loss: 0.1458\n",
            "Test Loss: 0.1221, Test Accuracy: 0.9654\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train = x_train / 255.0  # Normalize to [0, 1]\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode labels\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Define the RNN model\n",
        "class RNNModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn_layer = tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=False)\n",
        "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.rnn_layer(inputs)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = RNNModel()\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Compile model for convenience (for evaluation later)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# Dataset preparation\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size).shuffle(buffer_size=1024)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "\n",
        "# Training\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(x_batch)  # Forward pass\n",
        "            loss = loss_fn(y_batch, predictions)  # Calculate loss\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)  # Backpropagation\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # Update weights\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}, Loss: {loss.numpy():.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpnuqX7zmC/wgn1m7ntoMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}